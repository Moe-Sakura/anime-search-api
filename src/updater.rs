//! è§„åˆ™è‡ªåŠ¨æ›´æ–°å™¨
//! é€šè¿‡ GitHub API æ£€æµ‹ KazumiRules ä»“åº“å˜åŠ¨å¹¶åŒæ­¥è§„åˆ™

use crate::config::CONFIG;
use crate::http_client::HTTP_CLIENT;
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::Path;
use tracing::{debug, info, warn};

/// è§„åˆ™ç›®å½•
const RULES_DIR: &str = "rules";
/// å­˜å‚¨ä¸Šæ¬¡ commit SHA çš„æ–‡ä»¶
const LAST_COMMIT_FILE: &str = "rules/.last_commit";

/// å¸¦ä»£ç†é‡è¯•çš„ GET è¯·æ±‚
async fn get_with_retry(url: &str) -> anyhow::Result<reqwest::Response> {
    // ç¬¬ä¸€æ¬¡ç›´æ¥è¯·æ±‚
    let result = HTTP_CLIENT
        .get(url)
        .header("Accept", "application/vnd.github.v3+json")
        .header("User-Agent", "anime-search-api")
        .send()
        .await;

    match result {
        Ok(resp) if resp.status().is_success() => Ok(resp),
        Ok(resp) => {
            // çŠ¶æ€ç é”™è¯¯ï¼Œå°è¯•ä»£ç†
            let status = resp.status();
            debug!("è¯·æ±‚å¤±è´¥ ({}), å°è¯•ä»£ç†: {}", status, url);
            get_via_proxy(url).await
        }
        Err(e) => {
            // ç½‘ç»œé”™è¯¯ï¼Œå°è¯•ä»£ç†
            debug!("è¯·æ±‚å¤±è´¥ ({}), å°è¯•ä»£ç†: {}", e, url);
            get_via_proxy(url).await
        }
    }
}

/// é€šè¿‡ä»£ç†è¯·æ±‚
async fn get_via_proxy(url: &str) -> anyhow::Result<reqwest::Response> {
    let proxy_url = format!("{}{}", CONFIG.github_proxy, url);
    debug!("ä½¿ç”¨ä»£ç†: {}", proxy_url);

    let response = HTTP_CLIENT
        .get(&proxy_url)
        .header("Accept", "application/vnd.github.v3+json")
        .header("User-Agent", "anime-search-api")
        .send()
        .await?;

    if !response.status().is_success() {
        anyhow::bail!("ä»£ç†è¯·æ±‚å¤±è´¥: HTTP {}", response.status());
    }

    Ok(response)
}

/// GitHub Commit å“åº”
#[derive(Debug, Deserialize)]
struct GitHubCommit {
    sha: String,
}

/// GitHub Contents å“åº” (æ–‡ä»¶åˆ—è¡¨)
#[derive(Debug, Deserialize)]
struct GitHubContent {
    name: String,
    #[serde(rename = "type")]
    content_type: String,
}

/// æ›´æ–°ç»“æœ
#[derive(Debug, Clone, Serialize)]
pub struct UpdateResult {
    pub total: usize,
    pub updated: usize,
    pub added: usize,
    pub failed: usize,
    pub details: Vec<UpdateDetail>,
}

#[derive(Debug, Clone, Serialize)]
pub struct UpdateDetail {
    pub name: String,
    pub action: String, // "added", "updated", "failed"
    pub message: String,
}

/// æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰è§„åˆ™æ–‡ä»¶
pub fn has_local_rules() -> bool {
    let rules_path = Path::new(RULES_DIR);
    if !rules_path.exists() {
        return false;
    }

    match fs::read_dir(rules_path) {
        Ok(entries) => entries
            .flatten()
            .any(|e| {
                let name = e.file_name();
                let name = name.to_string_lossy();
                name.ends_with(".json") && name != "index.json"
            }),
        Err(_) => false,
    }
}

/// è¯»å–ä¸Šæ¬¡çš„ commit SHA
fn read_last_commit() -> Option<String> {
    fs::read_to_string(LAST_COMMIT_FILE).ok().map(|s| s.trim().to_string())
}

/// ä¿å­˜å½“å‰ commit SHA
fn save_last_commit(sha: &str) -> anyhow::Result<()> {
    let _ = fs::create_dir_all(RULES_DIR);
    fs::write(LAST_COMMIT_FILE, sha)?;
    Ok(())
}

/// è·å–ä»“åº“æœ€æ–° commit SHA
async fn fetch_latest_commit() -> anyhow::Result<String> {
    let url = CONFIG.github_api_commits();
    let response = get_with_retry(&url).await?;
    let commit: GitHubCommit = response.json().await?;
    Ok(commit.sha)
}

/// è·å–ä»“åº“ä¸­çš„æ‰€æœ‰è§„åˆ™æ–‡ä»¶å
async fn fetch_rule_files() -> anyhow::Result<Vec<String>> {
    let url = CONFIG.github_api_contents();
    let response = get_with_retry(&url).await?;
    let contents: Vec<GitHubContent> = response.json().await?;

    // è¿‡æ»¤å‡º .json æ–‡ä»¶ï¼Œæ’é™¤ index.json
    let rule_files: Vec<String> = contents
        .into_iter()
        .filter(|c| {
            c.content_type == "file" && c.name.ends_with(".json") && c.name != "index.json"
        })
        .map(|c| c.name.trim_end_matches(".json").to_string())
        .collect();

    Ok(rule_files)
}

/// ä¸‹è½½å•ä¸ªè§„åˆ™
async fn download_rule(name: &str) -> anyhow::Result<String> {
    let url = format!("{}{}.json", CONFIG.github_raw_base(), name);
    let response = get_with_retry(&url).await?;
    let content = response.text().await?;

    // éªŒè¯ JSON æ ¼å¼
    serde_json::from_str::<serde_json::Value>(&content)?;

    Ok(content)
}

/// ä¿å­˜è§„åˆ™åˆ°æœ¬åœ°
fn save_rule(name: &str, content: &str) -> anyhow::Result<()> {
    let _ = fs::create_dir_all(RULES_DIR);
    let path = Path::new(RULES_DIR).join(format!("{}.json", name));
    fs::write(path, content)?;
    Ok(())
}

/// æ£€æŸ¥æœ¬åœ°æ˜¯å¦å­˜åœ¨è¯¥è§„åˆ™
fn rule_exists(name: &str) -> bool {
    Path::new(RULES_DIR).join(format!("{}.json", name)).exists()
}

/// æ£€æµ‹å˜åŠ¨å¹¶æ›´æ–°è§„åˆ™
pub async fn update_rules() -> UpdateResult {
    let mut result = UpdateResult {
        total: 0,
        updated: 0,
        added: 0,
        failed: 0,
        details: Vec::new(),
    };

    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶æ›´æ–°ï¼ˆæœ¬åœ°æ— è§„åˆ™ï¼‰
    let force_update = !has_local_rules();
    if force_update {
        info!("ğŸ“¦ æœ¬åœ°æ— è§„åˆ™æ–‡ä»¶ï¼Œç«‹å³æ‹‰å–...");
    }

    // è·å–æœ€æ–° commit SHA
    let latest_commit = match fetch_latest_commit().await {
        Ok(sha) => sha,
        Err(e) => {
            warn!("è·å–æœ€æ–° commit å¤±è´¥: {}", e);
            result.details.push(UpdateDetail {
                name: "commit".to_string(),
                action: "failed".to_string(),
                message: format!("è·å– commit å¤±è´¥: {}", e),
            });
            return result;
        }
    };

    debug!("æœ€æ–° commit: {}", &latest_commit[..7]);

    // æ£€æŸ¥æ˜¯å¦æœ‰å˜åŠ¨
    let last_commit = read_last_commit();
    let has_changes = force_update || last_commit.as_ref() != Some(&latest_commit);

    if !has_changes {
        info!("ğŸ“‹ è§„åˆ™æ— å˜åŠ¨ (commit: {})", &latest_commit[..7]);
        return result;
    }

    info!(
        "ğŸ”„ æ£€æµ‹åˆ°å˜åŠ¨: {} -> {}",
        last_commit.as_ref().map(|s| &s[..7]).unwrap_or("æ— "),
        &latest_commit[..7]
    );

    // è·å–è§„åˆ™æ–‡ä»¶åˆ—è¡¨
    let rule_files = match fetch_rule_files().await {
        Ok(files) => files,
        Err(e) => {
            warn!("è·å–è§„åˆ™åˆ—è¡¨å¤±è´¥: {}", e);
            result.details.push(UpdateDetail {
                name: "contents".to_string(),
                action: "failed".to_string(),
                message: format!("è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {}", e),
            });
            return result;
        }
    };

    result.total = rule_files.len();
    info!("ğŸ“¡ å‘ç° {} ä¸ªè§„åˆ™æ–‡ä»¶", rule_files.len());

    // ä¸‹è½½å¹¶ä¿å­˜æ¯ä¸ªè§„åˆ™
    for name in rule_files {
        let is_new = !rule_exists(&name);

        match download_rule(&name).await {
            Ok(content) => {
                if let Err(e) = save_rule(&name, &content) {
                    warn!("ä¿å­˜è§„åˆ™ {} å¤±è´¥: {}", name, e);
                    result.failed += 1;
                    result.details.push(UpdateDetail {
                        name: name.clone(),
                        action: "failed".to_string(),
                        message: format!("ä¿å­˜å¤±è´¥: {}", e),
                    });
                } else {
                    if is_new {
                        result.added += 1;
                        debug!("â• æ–°å¢è§„åˆ™: {}", name);
                    } else {
                        result.updated += 1;
                        debug!("ğŸ”„ æ›´æ–°è§„åˆ™: {}", name);
                    }
                    result.details.push(UpdateDetail {
                        name: name.clone(),
                        action: if is_new { "added" } else { "updated" }.to_string(),
                        message: "ok".to_string(),
                    });
                }
            }
            Err(e) => {
                warn!("ä¸‹è½½è§„åˆ™ {} å¤±è´¥: {}", name, e);
                result.failed += 1;
                result.details.push(UpdateDetail {
                    name: name.clone(),
                    action: "failed".to_string(),
                    message: format!("ä¸‹è½½å¤±è´¥: {}", e),
                });
            }
        }
    }

    // ä¿å­˜å½“å‰ commit SHA
    if let Err(e) = save_last_commit(&latest_commit) {
        warn!("ä¿å­˜ commit SHA å¤±è´¥: {}", e);
    }

    info!(
        "âœ… æ›´æ–°å®Œæˆ: {} æ–°å¢, {} æ›´æ–°, {} å¤±è´¥",
        result.added, result.updated, result.failed
    );

    result
}

/// æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆä»…æ£€æŸ¥ï¼Œä¸æ‰§è¡Œæ›´æ–°ï¼‰
#[allow(dead_code)]
pub async fn check_for_updates() -> bool {
    if !has_local_rules() {
        return true;
    }

    match fetch_latest_commit().await {
        Ok(latest) => {
            let last = read_last_commit();
            last.as_ref() != Some(&latest)
        }
        Err(_) => false,
    }
}